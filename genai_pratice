import streamlit as st
import ollama

# Streamlit page settings
st.set_page_config(page_title="SAS to SQL Chatbot", layout="wide")
st.title("ðŸ’¬ SAS â†’ SQL Conversion Chatbot (Llama 3.1 / Ollama)")

# Initialize chat history
if "messages" not in st.session_state:
    st.session_state["messages"] = []

# Display previous conversation
for msg in st.session_state["messages"]:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])

# Chat input
prompt = st.chat_input("Paste SAS code or ask something...")

# Function using ollama.chat (maintains context)
def query_ollama(messages):
    response = ollama.chat(
        model="llama3.1",   # model name fixed
        messages=messages   # send FULL chat history
    )
    return response["message"]["content"]

# When user enters text
if prompt:
    # Add user message to history
    st.session_state["messages"].append({"role": "user", "content": prompt})

    # Generate bot reply using full history
    with st.chat_message("assistant"):
        with st.spinner("Thinking..."):
            output = query_ollama(st.session_state["messages"])
            st.write(output)

    # Save assistant reply
    st.session_state["messages"].append({"role": "assistant", "content": output})
